# python으로 웹 스크래퍼 만들기(2.3 ~ 2.5)
```
soup : 어떤 데이터를 찾아주는 object, soup를 이용해서 데이터를 탐색하고 추출할 수 있다.
indeed_soup.find("div", {"class":"pagination"})
-> div를 찾아서 class 명이 pagination인 요소를 반환

```
## BeautifulSoup : 데이터 추출
### 1. 페이지가 총 몇개인지 확인
```
import requests
from bs4 import BeautifulSoup

# indeed 사이트에서 고급검색에서 일자리를 50개씩 볼 수 있도록 변경후 
# requests.get()안에 넣어서 url을 가져옴
indeed_result = requests.get("https://www.indeed.com/jobs?as_and=python&as_phr&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary&radius=25&l&fromage=any&limit=50")

# BeautifulSoup를 이용해 가져온 url을 html.parser를 사용해서 indeed_soup에 넣어줌
indeed_soup = BeautifulSoup(indeed_result.text, "html.parser")
```
> soup에는 많은 함수들이 있는데 find_all()을 사용
```
# pagination을 개발자도구로 보게되면 아래의 사진과 같이 보여짐 <div><a><span></span></a></div>
```
![1  개발자 도구를 이용해서 스크래핑할 웹사이트의 페이지](https://user-images.githubusercontent.com/71562490/129292496-149965ce-4557-4b9b-893c-9f56fd4f5ded.JPG)

```
pagination = indeed_soup.find("div", {"class":"pagination"})

# a태그안에 링크들을 찾아서 links 배열에 넣어줌
links = pagination.find_all('a')

# 빈 배열을 만들어주고
pages = []

# links에 있는 link(원소값)마다
for link in links:  
  
  # page(<span>)를 찾아주도록 해서 page 찾은 걸 pages라는 배열에 넣어줌
  pages.append(link.find("span"))
  
  # 결과는 아래의 사진과 같이 나옴
```
![2  마지막줄 빼기](https://user-images.githubusercontent.com/71562490/129292580-e9c99bb1-110b-4c46-934f-2d9f8df94f77.JPG)
```
# 그리고 마지막줄은 빼줌
# print(pages[:-1]) # page를 모두 가져오되 마지막 것은 제외
pages = pages[:-1]
print(pages)
```
--------------------------
> 텍스트만을 추출할 수 있는 soup.~.string 사용
```
pages.append(link.find("span").string) # ['2', '3', '4', '5']
```
```
link안에 string이 하나라면 그냥 string method를 이용하면 아래와 같이 써도 된다.
```
```
pages.append(link.string) # ['2', '3', '4', '5']
```
--------------------------
> 리스트에 있는 String값을 int형으로 변환
```
for link in links:
  pages.append(int(link.string))
  
print(pages)
```
```
print(link.string) # ['2', '3', '4', '5', None] 이라고 뜨는데 None은 int형으로 바꿀 수 없다.
```
![3_1](https://user-images.githubusercontent.com/71562490/129296705-c6341c32-cc17-4622-aa43-c276df7c7385.JPG)
```
그래서 에러가 나기 때문에 미리 방지를 해줘야된다.
```
![3](https://user-images.githubusercontent.com/71562490/129296586-55594b14-7892-471a-b172-7d63481391b5.JPG)
```
# links 원소 마지막인(None)을 뺀채로 int형으로 변환
for link in links[:-1]:
  pages.append(int(link.string))

print(pages) # [2, 3, 4, 5]
```
--------------------------
> 마지막 페이지를 출력
```
print(pages[-1]) # 5
```
--------------------------
### 2. 페이지마다 목록의 개수를 구하기
```
max_page = pages[-1]

for n in range(max_page):
  print(n) # 0 ~ 19 총 20개
```
> range의 현재값을 indeed에서 가져온 요소 개수만큼 곱해줌(n*50)
```
for n in range(max_page):
  print(f"start={n*50}")
```
<img src="https://user-images.githubusercontent.com/71562490/129297901-44489757-0f78-4a49-84d4-e18579844164.JPG" width="500" height="450"> | <img src="https://user-images.githubusercontent.com/71562490/129297918-92d53e17-f68d-4855-9332-6ff78da69b7d.JPG" width="100" height="250">
```
start=0 일 때 1페이지로 간다.
```













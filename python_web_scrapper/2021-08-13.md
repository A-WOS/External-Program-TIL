# python으로 웹 스크래퍼 만들기(2.3 ~ 2.5)
```
soup : 어떤 데이터를 찾아주는 object, soup를 이용해서 데이터를 탐색하고 추출할 수 있다.
indeed_soup.find("div", {"class":"pagination"})
-> div를 찾아서 class 명이 pagination인 요소를 반환

```
> BeautifulSoup : 데이터 추출
> > 페이지가 총 몇개인지 확인
```
import requests
from bs4 import BeautifulSoup

# indeed 사이트에서 고급검색에서 일자리를 50개씩 볼 수 있도록 변경후 
# requests.get()안에 넣어서 url을 가져옴
indeed_result = requests.get("https://www.indeed.com/jobs?as_and=python&as_phr&as_any&as_not&as_ttl&as_cmp&jt=all&st&salary&radius=25&l&fromage=any&limit=50")

# BeautifulSoup를 이용해 가져온 url을 html.parser를 사용해서 indeed_soup에 넣어줌
indeed_soup = BeautifulSoup(indeed_result.text, "html.parser")
```
> > > soup에는 많은 함수들이 있는데 find_all()을 사용
```
# pagination을 개발자도구로 보게되면 아래의 사진과 같이 보여짐 <div><a><span></span></a></div>
```
![1  개발자 도구를 이용해서 스크래핑할 웹사이트의 페이지](https://user-images.githubusercontent.com/71562490/129292496-149965ce-4557-4b9b-893c-9f56fd4f5ded.JPG)

```
pagination = indeed_soup.find("div", {"class":"pagination"})

# a태그안에 링크들을 찾아서 links 배열에 넣어줌
links = pagination.find_all('a')

# 빈 배열을 만들어주고
pages = []

# links에 있는 link(원소값)마다
for link in links:  
  
  # page(<span>)를 찾아주도록 해서 page 찾은 걸 pages라는 배열에 넣어줌
  pages.append(link.find("span"))
  
  # 결과는 아래의 사진과 같이 나옴
```
![2  마지막줄 빼기](https://user-images.githubusercontent.com/71562490/129292580-e9c99bb1-110b-4c46-934f-2d9f8df94f77.JPG)
```
# 그리고 마지막줄은 빼줌
# print(pages[:-1]) # page를 모두 가져오되 마지막 것은 제외
pages = pages[:-1]
print(pages)
```
> > > 텍스트만을 추출할 수 있는 soup.~.string 사용
```
pages.append(link.find("span").string) # ['2', '3', '4', '5']
```
```
link안에 string이 하나라면 그냥 string method를 이용하면 아래와 같이 써도 된다.
```
```
pages.append(link.string) # ['2', '3', '4', '5']
```















